# GPT2 LoveCraft


This project generate LoveCraft fiction using GPT-2 model.

Fine tuning data: [Kaggle](https://www.kaggle.com/bennijesus/lovecraft-fiction)

### Model information


    Base model: gpt-2 large
    Epoch: 30
    Train runtime:  secs
    Loss: 



### How to use

    * First, Fill what the base text. This will be base of LoveCraft fiction.
    * And then, Fill number in length. Text is created as long as "length". I recommend between 100 and 300.
    * If length is so big, generate time will be long.

### Post parameter

    text: The base of LoveCraft fiction.
    length: The size of generated text.


### Output format

    {"0": generated text}


## * With CLI *

### Input example


    

### Output example




## * With swagger *

API page: [Ainize]()

## * With a Demo *

Demo page: [End-point]()